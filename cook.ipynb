{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_normalized</th>\n",
       "      <th>production_normalized</th>\n",
       "      <th>price_normalized</th>\n",
       "      <th>priceXproduction_normalized</th>\n",
       "      <th>price2_normalized</th>\n",
       "      <th>production2_normalized</th>\n",
       "      <th>temperature2_normalized</th>\n",
       "      <th>priceXproduction2_normalized</th>\n",
       "      <th>price3_normalized</th>\n",
       "      <th>production3_normalized</th>\n",
       "      <th>temperature3_normalized</th>\n",
       "      <th>priceXproduction3_normalized</th>\n",
       "      <th>weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616553</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>0.634733</td>\n",
       "      <td>0.201437</td>\n",
       "      <td>0.445617</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.464424</td>\n",
       "      <td>0.179461</td>\n",
       "      <td>0.309059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326993</td>\n",
       "      <td>0.283779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.539809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297433</td>\n",
       "      <td>0.182375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.281432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.069785</td>\n",
       "      <td>0.132881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026859</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.056574</td>\n",
       "      <td>0.345037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511454</td>\n",
       "      <td>0.081073</td>\n",
       "      <td>0.794433</td>\n",
       "      <td>0.139840</td>\n",
       "      <td>0.772505</td>\n",
       "      <td>0.027207</td>\n",
       "      <td>0.238462</td>\n",
       "      <td>0.051482</td>\n",
       "      <td>0.749690</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.116544</td>\n",
       "      <td>0.016481</td>\n",
       "      <td>0.292252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.747821</td>\n",
       "      <td>0.423607</td>\n",
       "      <td>0.956103</td>\n",
       "      <td>0.571659</td>\n",
       "      <td>0.950467</td>\n",
       "      <td>0.247069</td>\n",
       "      <td>0.541523</td>\n",
       "      <td>0.391788</td>\n",
       "      <td>0.944442</td>\n",
       "      <td>0.133999</td>\n",
       "      <td>0.398564</td>\n",
       "      <td>0.256058</td>\n",
       "      <td>0.546925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature_normalized  production_normalized  price_normalized  \\\n",
       "0                0.000000               0.616553          0.224839   \n",
       "1                0.042947               1.000000          0.162741   \n",
       "2                0.297433               0.182375          1.000000   \n",
       "3                0.511454               0.081073          0.794433   \n",
       "4                0.747821               0.423607          0.956103   \n",
       "\n",
       "   priceXproduction_normalized  price2_normalized  production2_normalized  \\\n",
       "0                     0.634733           0.201437                0.445617   \n",
       "1                     1.000000           0.144445                1.000000   \n",
       "2                     0.281432           1.000000                0.074561   \n",
       "3                     0.139840           0.772505                0.027207   \n",
       "4                     0.571659           0.950467                0.247069   \n",
       "\n",
       "   temperature2_normalized  priceXproduction2_normalized  price3_normalized  \\\n",
       "0                 0.002235                      0.464424           0.179461   \n",
       "1                 0.000000                      1.000000           0.127467   \n",
       "2                 0.069785                      0.132881           1.000000   \n",
       "3                 0.238462                      0.051482           0.749690   \n",
       "4                 0.541523                      0.391788           0.944442   \n",
       "\n",
       "   production3_normalized  temperature3_normalized  \\\n",
       "0                0.309059                 0.000000   \n",
       "1                1.000000                 0.000106   \n",
       "2                0.026859                 0.018541   \n",
       "3                0.007854                 0.116544   \n",
       "4                0.133999                 0.398564   \n",
       "\n",
       "   priceXproduction3_normalized  weighted_score  \n",
       "0                      0.326993        0.283779  \n",
       "1                      1.000000        0.539809  \n",
       "2                      0.056574        0.345037  \n",
       "3                      0.016481        0.292252  \n",
       "4                      0.256058        0.546925  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv, sklearn, os\n",
    "\n",
    "filename = \"Wheat.csv\"\n",
    "\n",
    "def load_csv(csv_file):\n",
    "    data_dir = os.path.join(os.getcwd(), 'data', csv_file)\n",
    "\n",
    "    with open(data_dir, 'r') as file:\n",
    "        df = pd.read_csv(file)\n",
    "        df.rename(columns={'value': 'temperature'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "df=load_csv(filename)\n",
    "\n",
    "def normalize_column(data, column_name):\n",
    "    \"\"\"\n",
    "    Normalizes the specified column in the DataFrame using Min-Max scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Pandas DataFrame containing the data.\n",
    "    - column_name: The name of the column to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    - A Pandas DataFrame with the specified column normalized.\n",
    "    \"\"\"\n",
    "    min_val = data[column_name].min()\n",
    "    max_val = data[column_name].max()\n",
    "    data[column_name + '_normalized'] = (data[column_name] - min_val) / (max_val - min_val)\n",
    "    return data\n",
    "\n",
    "# Normalize the 'price', 'production', and 'value' (temperature) columns\n",
    "norm_df= df.copy()\n",
    "norm_df['priceXproduction'] = norm_df['price'] * norm_df['production']\n",
    "norm_df['price2'] = norm_df['price'] ** 2\n",
    "norm_df['production2'] = norm_df['production'] ** 2\n",
    "norm_df['temperature2'] = norm_df['temperature'] ** 2\n",
    "norm_df['priceXproduction2'] = norm_df['priceXproduction'] ** 2\n",
    "norm_df['price3'] = norm_df['price'] ** 3\n",
    "norm_df['production3'] = norm_df['production'] ** 3\n",
    "norm_df['temperature3'] = norm_df['temperature'] ** 3\n",
    "norm_df['priceXproduction3'] = norm_df['priceXproduction'] ** 3\n",
    "norm_cols = norm_df.columns[1:]\n",
    "for column in norm_cols:\n",
    "    norm_df = normalize_column(norm_df, column)\n",
    "    \n",
    "norm_df = norm_df.filter(like='_normalized')\n",
    "norm_df['weighted_score'] = norm_df.mean(axis=1)\n",
    "\n",
    "norm_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyson\\AppData\\Local\\Temp\\ipykernel_14784\\1988174306.py:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_normalized</th>\n",
       "      <th>production_normalized</th>\n",
       "      <th>price_normalized</th>\n",
       "      <th>weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616553</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>0.283779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162741</td>\n",
       "      <td>0.539809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297433</td>\n",
       "      <td>0.182375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511454</td>\n",
       "      <td>0.081073</td>\n",
       "      <td>0.794433</td>\n",
       "      <td>0.292252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.747821</td>\n",
       "      <td>0.423607</td>\n",
       "      <td>0.956103</td>\n",
       "      <td>0.546925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.937377</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.978587</td>\n",
       "      <td>0.504145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398637</td>\n",
       "      <td>0.109208</td>\n",
       "      <td>0.396515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.990388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.856253</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.063169</td>\n",
       "      <td>0.211410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.052920</td>\n",
       "      <td>0.388651</td>\n",
       "      <td>0.190379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.252539</td>\n",
       "      <td>0.509090</td>\n",
       "      <td>0.304069</td>\n",
       "      <td>0.275468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.046697</td>\n",
       "      <td>0.039615</td>\n",
       "      <td>0.020180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.050866</td>\n",
       "      <td>0.616553</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>0.287843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperature_normalized  production_normalized  price_normalized  \\\n",
       "0                 0.000000               0.616553          0.224839   \n",
       "1                 0.042947               1.000000          0.162741   \n",
       "2                 0.297433               0.182375          1.000000   \n",
       "3                 0.511454               0.081073          0.794433   \n",
       "4                 0.747821               0.423607          0.956103   \n",
       "5                 0.937377               0.120499          0.978587   \n",
       "6                 1.000000               0.398637          0.109208   \n",
       "7                 0.990388               0.000000          0.000000   \n",
       "8                 0.856253               0.063448          0.063169   \n",
       "9                 0.567164               0.052920          0.388651   \n",
       "10                0.252539               0.509090          0.304069   \n",
       "11                0.007045               0.046697          0.039615   \n",
       "12                0.050866               0.616553          0.224839   \n",
       "\n",
       "    weighted_score  \n",
       "0         0.283779  \n",
       "1         0.539809  \n",
       "2         0.345037  \n",
       "3         0.292252  \n",
       "4         0.546925  \n",
       "5         0.504145  \n",
       "6         0.396515  \n",
       "7         0.245038  \n",
       "8         0.211410  \n",
       "9         0.190379  \n",
       "10        0.275468  \n",
       "11        0.020180  \n",
       "12        0.287843  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = norm_df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "\n",
    "# Drop highly correlated columns\n",
    "norm_df_reduced = norm_df.drop(to_drop, axis=1)\n",
    "\n",
    "norm_df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_normalized</th>\n",
       "      <th>production_normalized</th>\n",
       "      <th>price_normalized</th>\n",
       "      <th>priceXproduction_normalized</th>\n",
       "      <th>price2_normalized</th>\n",
       "      <th>production2_normalized</th>\n",
       "      <th>temperature2_normalized</th>\n",
       "      <th>priceXproduction2_normalized</th>\n",
       "      <th>price3_normalized</th>\n",
       "      <th>production3_normalized</th>\n",
       "      <th>temperature3_normalized</th>\n",
       "      <th>priceXproduction3_normalized</th>\n",
       "      <th>weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature_normalized</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.530007</td>\n",
       "      <td>0.158106</td>\n",
       "      <td>0.506351</td>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.536337</td>\n",
       "      <td>0.963445</td>\n",
       "      <td>0.519900</td>\n",
       "      <td>0.179416</td>\n",
       "      <td>0.509660</td>\n",
       "      <td>0.920488</td>\n",
       "      <td>0.501434</td>\n",
       "      <td>0.247581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production_normalized</th>\n",
       "      <td>0.530007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159370</td>\n",
       "      <td>0.988079</td>\n",
       "      <td>0.169740</td>\n",
       "      <td>0.972608</td>\n",
       "      <td>0.446333</td>\n",
       "      <td>0.978231</td>\n",
       "      <td>0.178869</td>\n",
       "      <td>0.909090</td>\n",
       "      <td>0.390238</td>\n",
       "      <td>0.926599</td>\n",
       "      <td>0.518812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_normalized</th>\n",
       "      <td>0.158106</td>\n",
       "      <td>0.159370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.223090</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.117209</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.241980</td>\n",
       "      <td>0.083132</td>\n",
       "      <td>0.170415</td>\n",
       "      <td>0.513239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priceXproduction_normalized</th>\n",
       "      <td>0.506351</td>\n",
       "      <td>0.988079</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026410</td>\n",
       "      <td>0.946473</td>\n",
       "      <td>0.445973</td>\n",
       "      <td>0.972606</td>\n",
       "      <td>0.035356</td>\n",
       "      <td>0.875405</td>\n",
       "      <td>0.402228</td>\n",
       "      <td>0.908662</td>\n",
       "      <td>0.600995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price2_normalized</th>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.169740</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.026410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232039</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>0.125849</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.249196</td>\n",
       "      <td>0.067956</td>\n",
       "      <td>0.177492</td>\n",
       "      <td>0.513975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production2_normalized</th>\n",
       "      <td>0.536337</td>\n",
       "      <td>0.972608</td>\n",
       "      <td>0.223090</td>\n",
       "      <td>0.946473</td>\n",
       "      <td>0.232039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.446104</td>\n",
       "      <td>0.990094</td>\n",
       "      <td>0.239853</td>\n",
       "      <td>0.980587</td>\n",
       "      <td>0.389049</td>\n",
       "      <td>0.984068</td>\n",
       "      <td>0.491842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature2_normalized</th>\n",
       "      <td>0.963445</td>\n",
       "      <td>0.446333</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.445973</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>0.446104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.446980</td>\n",
       "      <td>0.022320</td>\n",
       "      <td>0.421921</td>\n",
       "      <td>0.990016</td>\n",
       "      <td>0.425424</td>\n",
       "      <td>0.235233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priceXproduction2_normalized</th>\n",
       "      <td>0.519900</td>\n",
       "      <td>0.978231</td>\n",
       "      <td>0.117209</td>\n",
       "      <td>0.972606</td>\n",
       "      <td>0.125849</td>\n",
       "      <td>0.990094</td>\n",
       "      <td>0.446980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133432</td>\n",
       "      <td>0.960200</td>\n",
       "      <td>0.400281</td>\n",
       "      <td>0.980180</td>\n",
       "      <td>0.563007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price3_normalized</th>\n",
       "      <td>0.179416</td>\n",
       "      <td>0.178869</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.035356</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.239853</td>\n",
       "      <td>0.022320</td>\n",
       "      <td>0.133432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255430</td>\n",
       "      <td>0.053577</td>\n",
       "      <td>0.183629</td>\n",
       "      <td>0.514683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production3_normalized</th>\n",
       "      <td>0.509660</td>\n",
       "      <td>0.909090</td>\n",
       "      <td>0.241980</td>\n",
       "      <td>0.875405</td>\n",
       "      <td>0.249196</td>\n",
       "      <td>0.980587</td>\n",
       "      <td>0.421921</td>\n",
       "      <td>0.960200</td>\n",
       "      <td>0.255430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368180</td>\n",
       "      <td>0.992771</td>\n",
       "      <td>0.470219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature3_normalized</th>\n",
       "      <td>0.920488</td>\n",
       "      <td>0.390238</td>\n",
       "      <td>0.083132</td>\n",
       "      <td>0.402228</td>\n",
       "      <td>0.067956</td>\n",
       "      <td>0.389049</td>\n",
       "      <td>0.990016</td>\n",
       "      <td>0.400281</td>\n",
       "      <td>0.053577</td>\n",
       "      <td>0.368180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379531</td>\n",
       "      <td>0.224840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priceXproduction3_normalized</th>\n",
       "      <td>0.501434</td>\n",
       "      <td>0.926599</td>\n",
       "      <td>0.170415</td>\n",
       "      <td>0.908662</td>\n",
       "      <td>0.177492</td>\n",
       "      <td>0.984068</td>\n",
       "      <td>0.425424</td>\n",
       "      <td>0.980180</td>\n",
       "      <td>0.183629</td>\n",
       "      <td>0.992771</td>\n",
       "      <td>0.379531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_score</th>\n",
       "      <td>0.247581</td>\n",
       "      <td>0.518812</td>\n",
       "      <td>0.513239</td>\n",
       "      <td>0.600995</td>\n",
       "      <td>0.513975</td>\n",
       "      <td>0.491842</td>\n",
       "      <td>0.235233</td>\n",
       "      <td>0.563007</td>\n",
       "      <td>0.514683</td>\n",
       "      <td>0.470219</td>\n",
       "      <td>0.224840</td>\n",
       "      <td>0.527398</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              temperature_normalized  production_normalized  \\\n",
       "temperature_normalized                      1.000000               0.530007   \n",
       "production_normalized                       0.530007               1.000000   \n",
       "price_normalized                            0.158106               0.159370   \n",
       "priceXproduction_normalized                 0.506351               0.988079   \n",
       "price2_normalized                           0.169249               0.169740   \n",
       "production2_normalized                      0.536337               0.972608   \n",
       "temperature2_normalized                     0.963445               0.446333   \n",
       "priceXproduction2_normalized                0.519900               0.978231   \n",
       "price3_normalized                           0.179416               0.178869   \n",
       "production3_normalized                      0.509660               0.909090   \n",
       "temperature3_normalized                     0.920488               0.390238   \n",
       "priceXproduction3_normalized                0.501434               0.926599   \n",
       "weighted_score                              0.247581               0.518812   \n",
       "\n",
       "                              price_normalized  priceXproduction_normalized  \\\n",
       "temperature_normalized                0.158106                     0.506351   \n",
       "production_normalized                 0.159370                     0.988079   \n",
       "price_normalized                      1.000000                     0.016332   \n",
       "priceXproduction_normalized           0.016332                     1.000000   \n",
       "price2_normalized                     0.999605                     0.026410   \n",
       "production2_normalized                0.223090                     0.946473   \n",
       "temperature2_normalized               0.005095                     0.445973   \n",
       "priceXproduction2_normalized          0.117209                     0.972606   \n",
       "price3_normalized                     0.998486                     0.035356   \n",
       "production3_normalized                0.241980                     0.875405   \n",
       "temperature3_normalized               0.083132                     0.402228   \n",
       "priceXproduction3_normalized          0.170415                     0.908662   \n",
       "weighted_score                        0.513239                     0.600995   \n",
       "\n",
       "                              price2_normalized  production2_normalized  \\\n",
       "temperature_normalized                 0.169249                0.536337   \n",
       "production_normalized                  0.169740                0.972608   \n",
       "price_normalized                       0.999605                0.223090   \n",
       "priceXproduction_normalized            0.026410                0.946473   \n",
       "price2_normalized                      1.000000                0.232039   \n",
       "production2_normalized                 0.232039                1.000000   \n",
       "temperature2_normalized                0.009053                0.446104   \n",
       "priceXproduction2_normalized           0.125849                0.990094   \n",
       "price3_normalized                      0.999637                0.239853   \n",
       "production3_normalized                 0.249196                0.980587   \n",
       "temperature3_normalized                0.067956                0.389049   \n",
       "priceXproduction3_normalized           0.177492                0.984068   \n",
       "weighted_score                         0.513975                0.491842   \n",
       "\n",
       "                              temperature2_normalized  \\\n",
       "temperature_normalized                       0.963445   \n",
       "production_normalized                        0.446333   \n",
       "price_normalized                             0.005095   \n",
       "priceXproduction_normalized                  0.445973   \n",
       "price2_normalized                            0.009053   \n",
       "production2_normalized                       0.446104   \n",
       "temperature2_normalized                      1.000000   \n",
       "priceXproduction2_normalized                 0.446980   \n",
       "price3_normalized                            0.022320   \n",
       "production3_normalized                       0.421921   \n",
       "temperature3_normalized                      0.990016   \n",
       "priceXproduction3_normalized                 0.425424   \n",
       "weighted_score                               0.235233   \n",
       "\n",
       "                              priceXproduction2_normalized  price3_normalized  \\\n",
       "temperature_normalized                            0.519900           0.179416   \n",
       "production_normalized                             0.978231           0.178869   \n",
       "price_normalized                                  0.117209           0.998486   \n",
       "priceXproduction_normalized                       0.972606           0.035356   \n",
       "price2_normalized                                 0.125849           0.999637   \n",
       "production2_normalized                            0.990094           0.239853   \n",
       "temperature2_normalized                           0.446980           0.022320   \n",
       "priceXproduction2_normalized                      1.000000           0.133432   \n",
       "price3_normalized                                 0.133432           1.000000   \n",
       "production3_normalized                            0.960200           0.255430   \n",
       "temperature3_normalized                           0.400281           0.053577   \n",
       "priceXproduction3_normalized                      0.980180           0.183629   \n",
       "weighted_score                                    0.563007           0.514683   \n",
       "\n",
       "                              production3_normalized  temperature3_normalized  \\\n",
       "temperature_normalized                      0.509660                 0.920488   \n",
       "production_normalized                       0.909090                 0.390238   \n",
       "price_normalized                            0.241980                 0.083132   \n",
       "priceXproduction_normalized                 0.875405                 0.402228   \n",
       "price2_normalized                           0.249196                 0.067956   \n",
       "production2_normalized                      0.980587                 0.389049   \n",
       "temperature2_normalized                     0.421921                 0.990016   \n",
       "priceXproduction2_normalized                0.960200                 0.400281   \n",
       "price3_normalized                           0.255430                 0.053577   \n",
       "production3_normalized                      1.000000                 0.368180   \n",
       "temperature3_normalized                     0.368180                 1.000000   \n",
       "priceXproduction3_normalized                0.992771                 0.379531   \n",
       "weighted_score                              0.470219                 0.224840   \n",
       "\n",
       "                              priceXproduction3_normalized  weighted_score  \n",
       "temperature_normalized                            0.501434        0.247581  \n",
       "production_normalized                             0.926599        0.518812  \n",
       "price_normalized                                  0.170415        0.513239  \n",
       "priceXproduction_normalized                       0.908662        0.600995  \n",
       "price2_normalized                                 0.177492        0.513975  \n",
       "production2_normalized                            0.984068        0.491842  \n",
       "temperature2_normalized                           0.425424        0.235233  \n",
       "priceXproduction2_normalized                      0.980180        0.563007  \n",
       "price3_normalized                                 0.183629        0.514683  \n",
       "production3_normalized                            0.992771        0.470219  \n",
       "temperature3_normalized                           0.379531        0.224840  \n",
       "priceXproduction3_normalized                      1.000000        0.527398  \n",
       "weighted_score                                    0.527398        1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.02569169650019246 \n",
      "Root Mean Squared Error: 0.16028629542226142 \n",
      "R^2 Score: -0.042388092725979876\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare the data\n",
    "X = norm_df_reduced.drop(columns=['weighted_score'])  # Features (remove the target column and any non-feature columns)\n",
    "y = norm_df_reduced['weighted_score']  # Target variable\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# 3. Create the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=1000) # Use RandomForestRegressor if it's a regression problem\n",
    "\n",
    "# 4. Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2s = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse} \\nRoot Mean Squared Error: {rmse} \\nR^2 Score: {r2s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.015 (+/- 0.007)\n",
      "Root Mean Squared Error: 0.119 (+/- 0.029)\n",
      "R^2 Score: 0.274 (std: 0.171)\n"
     ]
    }
   ],
   "source": [
    "X = norm_df_reduced.drop(columns=['weighted_score'])  # Features (remove the target column and any non-feature columns)\n",
    "y = norm_df_reduced['weighted_score']  # Target variable\n",
    "\n",
    "# Create a random forest regressor model\n",
    "model = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "# Configure the cross-validation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "\n",
    "# Define multiple scoring metrics\n",
    "scoring = {'MSE': 'neg_mean_squared_error', 'R2': 'r2'}\n",
    "\n",
    "# Execute the cross-validation procedure using mean squared error\n",
    "scores = cross_validate(model, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "\n",
    "# Convert scores to positive as cross_val_score returns negative values for MSE to optimize towards zero\n",
    "mse_scores = -scores['test_MSE']\n",
    "\n",
    "# Report performance\n",
    "print(f'Mean Squared Error: {mse_scores.mean():.3f} (+/- {mse_scores.std():.3f})')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(mse_scores).mean():.3f} (+/- {np.sqrt(mse_scores).std():.3f})')\n",
    "print(f\"R^2 Score: {scores['test_R2'].mean():.3f} (std: {scores['test_R2'].std():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best parameters found:  {'bootstrap': True, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test set score of best estimator:  -5.074439374217088\n"
     ]
    }
   ],
   "source": [
    "X = norm_df_reduced.drop(columns=['weighted_score'])  # Features (remove the target column and any non-feature columns)\n",
    "y = norm_df_reduced['weighted_score']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create a random forest regressor model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Define a grid of parameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Define multiple scoring metrics\n",
    "scoring = {'MSE': 'neg_mean_squared_error', 'R2': 'r2'}\n",
    "\n",
    "# Set up the grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring=\"r2\")\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print out the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Get the best estimator and evaluate it on the test set\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf_score = best_rf.score(X_test, y_test)\n",
    "print(\"Test set score of best estimator: \", best_rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.42940626, 0.33754798, 0.21037788, 0.21196552, 0.20577547,\n",
       "        0.26294045, 0.28180997, 0.28130662, 0.111509  , 0.25524981]),\n",
       "     temperature_normalized  production_normalized  price_normalized\n",
       " 1                 0.042947               1.000000          0.162741\n",
       " 6                 1.000000               0.398637          0.109208\n",
       " 9                 0.567164               0.052920          0.388651\n",
       " 8                 0.856253               0.063448          0.063169\n",
       " 7                 0.990388               0.000000          0.000000\n",
       " 3                 0.511454               0.081073          0.794433\n",
       " 10                0.252539               0.509090          0.304069\n",
       " 12                0.050866               0.616553          0.224839\n",
       " 11                0.007045               0.046697          0.039615\n",
       " 0                 0.000000               0.616553          0.224839,\n",
       " 1     0.539809\n",
       " 6     0.396515\n",
       " 9     0.190379\n",
       " 8     0.211410\n",
       " 7     0.245038\n",
       " 3     0.292252\n",
       " 10    0.275468\n",
       " 12    0.287843\n",
       " 11    0.020180\n",
       " 0     0.283779\n",
       " Name: weighted_score, dtype: float64,\n",
       "    temperature_normalized  production_normalized  price_normalized\n",
       " 2                0.297433               0.182375          1.000000\n",
       " 4                0.747821               0.423607          0.956103\n",
       " 5                0.937377               0.120499          0.978587,\n",
       " 2    0.345037\n",
       " 4    0.546925\n",
       " 5    0.504145\n",
       " Name: weighted_score, dtype: float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_rf.predict(X_train)\n",
    "predictions, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.42940626, 0.33754798, 0.21037788, 0.21196552, 0.20577547,\n",
       "        0.26294045, 0.28180997, 0.28130662, 0.111509  , 0.25524981]),\n",
       " 1     0.539809\n",
       " 6     0.396515\n",
       " 9     0.190379\n",
       " 8     0.211410\n",
       " 7     0.245038\n",
       " 3     0.292252\n",
       " 10    0.275468\n",
       " 12    0.287843\n",
       " 11    0.020180\n",
       " 0     0.283779\n",
       " Name: weighted_score, dtype: float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_rf.predict(X_train)\n",
    "predictions, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_normalized</th>\n",
       "      <th>production_normalized</th>\n",
       "      <th>price_normalized</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual_weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049843</td>\n",
       "      <td>0.668476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242051</td>\n",
       "      <td>0.240092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.456452</td>\n",
       "      <td>0.392462</td>\n",
       "      <td>0.485080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.307906</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.213093</td>\n",
       "      <td>0.347609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.480675</td>\n",
       "      <td>0.106476</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.262940</td>\n",
       "      <td>0.393975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.730981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.856452</td>\n",
       "      <td>0.211251</td>\n",
       "      <td>0.449671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.936296</td>\n",
       "      <td>0.132398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265477</td>\n",
       "      <td>0.583543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372211</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.327387</td>\n",
       "      <td>0.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.955764</td>\n",
       "      <td>0.118434</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>0.265477</td>\n",
       "      <td>0.501854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.844343</td>\n",
       "      <td>0.200646</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.251880</td>\n",
       "      <td>0.451636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.570290</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.182258</td>\n",
       "      <td>0.263243</td>\n",
       "      <td>0.284133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.248665</td>\n",
       "      <td>0.716928</td>\n",
       "      <td>0.469355</td>\n",
       "      <td>0.285959</td>\n",
       "      <td>0.430227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134426</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.214046</td>\n",
       "      <td>0.163731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.018981</td>\n",
       "      <td>0.668476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212172</td>\n",
       "      <td>0.224907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperature_normalized  production_normalized  price_normalized  \\\n",
       "0                 0.049843               0.668476          0.000000   \n",
       "1                 0.091407               1.000000          0.456452   \n",
       "2                 0.307906               0.037181          0.832258   \n",
       "3                 0.480675               0.106476          0.725806   \n",
       "4                 0.730981               0.000000          0.856452   \n",
       "5                 0.936296               0.132398          1.000000   \n",
       "6                 1.000000               0.372211          0.612903   \n",
       "7                 0.955764               0.118434          0.667742   \n",
       "8                 0.844343               0.200646          0.509677   \n",
       "9                 0.570290               0.120742          0.182258   \n",
       "10                0.248665               0.716928          0.469355   \n",
       "11                0.000000               0.134426          0.306452   \n",
       "12                0.018981               0.668476          0.000000   \n",
       "\n",
       "    predictions  actual_weighted_score  \n",
       "0      0.242051               0.240092  \n",
       "1      0.392462               0.485080  \n",
       "2      0.213093               0.347609  \n",
       "3      0.262940               0.393975  \n",
       "4      0.211251               0.449671  \n",
       "5      0.265477               0.583543  \n",
       "6      0.327387               0.578125  \n",
       "7      0.265477               0.501854  \n",
       "8      0.251880               0.451636  \n",
       "9      0.263243               0.284133  \n",
       "10     0.285959               0.430227  \n",
       "11     0.214046               0.163731  \n",
       "12     0.212172               0.224907  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=load_csv(\"Soybeans.csv\")\n",
    "for column in df.columns[1:]:\n",
    "    df = normalize_column(df, column)\n",
    "    \n",
    "df = df.filter(like='_normalized')\n",
    "#df['weighted_score'] = df.mean(axis=1)\n",
    "\n",
    "df[\"predictions\"] = best_rf.predict(df)\n",
    "df['actual_weighted_score'] = df.mean(axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyson\\AppData\\Local\\Temp\\ipykernel_14784\\536931795.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best parameters found:  {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Test set score of best estimator:  0.9538114748105538\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "\n",
    "df_soy=load_csv(\"Soybeans.csv\")\n",
    "df_corn=load_csv(\"Corn.csv\")\n",
    "df_wheat=load_csv(\"Wheat.csv\")\n",
    "df_animal_products=load_csv(\"Animal_Products.csv\")\n",
    "df_vegetables=load_csv(\"Vegetables.csv\")\n",
    "df_fruit=load_csv(\"Fruit.csv\")\n",
    "df_fish=load_csv(\"Fish.csv\")\n",
    "df_nuts=load_csv(\"Nuts.csv\")\n",
    "\n",
    "train_df = pd.concat([df_soy, df_corn, df_wheat, df_animal_products, df_vegetables, df_fruit, df_fish, df_nuts], ignore_index=True)\n",
    "train_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "\n",
    "train_df['priceXproduction'] = train_df['price'] * train_df['production']\n",
    "train_df['price2'] = train_df['price'] ** 2\n",
    "train_df['production2'] = train_df['production'] ** 2\n",
    "train_df['temperature2'] = train_df['temperature'] ** 2\n",
    "train_df['priceXproduction2'] = train_df['priceXproduction'] ** 2\n",
    "train_df['price3'] = train_df['price'] ** 3\n",
    "train_df['production3'] = train_df['production'] ** 3\n",
    "train_df['temperature3'] = train_df['temperature'] ** 3\n",
    "train_df['priceXproduction3'] = train_df['priceXproduction'] ** 3\n",
    "\n",
    "\n",
    "for col in train_df.columns:\n",
    "    train_df = normalize_column(train_df, col)\n",
    "train_df = train_df.filter(like='_normalized')\n",
    "train_df['weighted_score'] = train_df.mean(axis=1)\n",
    "\n",
    "\n",
    "corr_matrix = train_df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "train_df_reduced = train_df.drop(to_drop, axis=1)\n",
    "\n",
    "X = train_df_reduced.drop(columns=['weighted_score'])\n",
    "y = train_df_reduced['weighted_score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, n_jobs=-1, verbose=2, scoring=\"r2\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf_score = best_rf.score(X_test, y_test)\n",
    "print(\"Test set score of best estimator: \", best_rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.07024087, 0.20268178, 0.29650004, 0.23265809, 0.32050848,\n",
       "        0.05648228, 0.68093856, 0.13545592, 0.12850788, 0.07215858,\n",
       "        0.16088167, 0.16325319, 0.09280904, 0.1760565 , 0.61038681,\n",
       "        0.32175885, 0.35676043, 0.21065099, 0.27955626, 0.33062957,\n",
       "        0.1361623 , 0.15234897, 0.15154032, 0.09748629, 0.08344328,\n",
       "        0.16425968, 0.17257984, 0.08553895, 0.24235581, 0.26336236,\n",
       "        0.11198769, 0.28692922, 0.38381554, 0.08802235, 0.23984536,\n",
       "        0.15336905, 0.16190405, 0.23390198, 0.11153228, 0.13479666,\n",
       "        0.21624766, 0.25867832, 0.0840534 , 0.18449837, 0.26596031,\n",
       "        0.1823874 , 0.22778317, 0.27220951, 0.06618413, 0.11762788,\n",
       "        0.0728097 , 0.16984447, 0.16935557, 0.11313198, 0.47471138,\n",
       "        0.08085396, 0.24573413, 0.17214229, 0.34896132, 0.32883349,\n",
       "        0.09318417, 0.16688742, 0.1403467 , 0.32184285, 0.31678009,\n",
       "        0.19495261, 0.05182626, 0.12224666, 0.26522466, 0.11527012,\n",
       "        0.20852616, 0.1037261 , 0.67124227, 0.14447839, 0.15635557,\n",
       "        0.14951968, 0.06467103, 0.21455993, 0.25322569, 0.15156126,\n",
       "        0.14242024, 0.21322644, 0.28402281]),\n",
       " 52    0.068845\n",
       " 2     0.196675\n",
       " 17    0.307909\n",
       " 82    0.229276\n",
       " 5     0.330236\n",
       "         ...   \n",
       " 83    0.261817\n",
       " 67    0.149710\n",
       " 25    0.139394\n",
       " 68    0.219468\n",
       " 47    0.285152\n",
       " Name: weighted_score, Length: 83, dtype: float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_rf.predict(X_train)\n",
    "predictions, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.24132384, 0.28668003, 0.13977909, 0.08165749, 0.29977554,\n",
       "        0.05800647, 0.09100986, 0.18153106, 0.29679016, 0.11581563,\n",
       "        0.1009102 , 0.49319081, 0.06147618, 0.14153214, 0.1412348 ,\n",
       "        0.14295407, 0.21251632, 0.16386876, 0.17528166, 0.32508692,\n",
       "        0.3278269 ]),\n",
       " 22     0.232628\n",
       " 46     0.332434\n",
       " 80     0.134612\n",
       " 93     0.073851\n",
       " 43     0.268878\n",
       " 103    0.052760\n",
       " 78     0.086245\n",
       " 26     0.178760\n",
       " 30     0.352796\n",
       " 88     0.122900\n",
       " 95     0.100653\n",
       " 73     0.431646\n",
       " 91     0.059550\n",
       " 13     0.140882\n",
       " 12     0.129572\n",
       " 51     0.145900\n",
       " 15     0.208457\n",
       " 11     0.145016\n",
       " 37     0.161883\n",
       " 20     0.324003\n",
       " 18     0.341519\n",
       " Name: weighted_score, dtype: float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_rf.predict(X_test)\n",
    "predictions, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_normalized</th>\n",
       "      <th>production_normalized</th>\n",
       "      <th>price_normalized</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual_weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616553</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>0.253672</td>\n",
       "      <td>0.273766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162741</td>\n",
       "      <td>0.523014</td>\n",
       "      <td>0.432175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297433</td>\n",
       "      <td>0.182375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234033</td>\n",
       "      <td>0.428460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511454</td>\n",
       "      <td>0.081073</td>\n",
       "      <td>0.794433</td>\n",
       "      <td>0.243892</td>\n",
       "      <td>0.407713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.747821</td>\n",
       "      <td>0.423607</td>\n",
       "      <td>0.956103</td>\n",
       "      <td>0.301633</td>\n",
       "      <td>0.607291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.937377</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.978587</td>\n",
       "      <td>0.376986</td>\n",
       "      <td>0.603362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398637</td>\n",
       "      <td>0.109208</td>\n",
       "      <td>0.260099</td>\n",
       "      <td>0.441986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.990388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237793</td>\n",
       "      <td>0.307045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.856253</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.063169</td>\n",
       "      <td>0.239793</td>\n",
       "      <td>0.305666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.052920</td>\n",
       "      <td>0.388651</td>\n",
       "      <td>0.138380</td>\n",
       "      <td>0.286779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.252539</td>\n",
       "      <td>0.509090</td>\n",
       "      <td>0.304069</td>\n",
       "      <td>0.171787</td>\n",
       "      <td>0.309371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.046697</td>\n",
       "      <td>0.039615</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.039974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.050866</td>\n",
       "      <td>0.616553</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>0.253672</td>\n",
       "      <td>0.286483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperature_normalized  production_normalized  price_normalized  \\\n",
       "0                 0.000000               0.616553          0.224839   \n",
       "1                 0.042947               1.000000          0.162741   \n",
       "2                 0.297433               0.182375          1.000000   \n",
       "3                 0.511454               0.081073          0.794433   \n",
       "4                 0.747821               0.423607          0.956103   \n",
       "5                 0.937377               0.120499          0.978587   \n",
       "6                 1.000000               0.398637          0.109208   \n",
       "7                 0.990388               0.000000          0.000000   \n",
       "8                 0.856253               0.063448          0.063169   \n",
       "9                 0.567164               0.052920          0.388651   \n",
       "10                0.252539               0.509090          0.304069   \n",
       "11                0.007045               0.046697          0.039615   \n",
       "12                0.050866               0.616553          0.224839   \n",
       "\n",
       "    predictions  actual_weighted_score  \n",
       "0      0.253672               0.273766  \n",
       "1      0.523014               0.432175  \n",
       "2      0.234033               0.428460  \n",
       "3      0.243892               0.407713  \n",
       "4      0.301633               0.607291  \n",
       "5      0.376986               0.603362  \n",
       "6      0.260099               0.441986  \n",
       "7      0.237793               0.307045  \n",
       "8      0.239793               0.305666  \n",
       "9      0.138380               0.286779  \n",
       "10     0.171787               0.309371  \n",
       "11     0.066541               0.039974  \n",
       "12     0.253672               0.286483  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"Wheat.csv\"\n",
    "\n",
    "def predict_weighted_score(csv_file):\n",
    "    df=load_csv(csv_file)\n",
    "    for column in df.columns[1:]:\n",
    "        df = normalize_column(df, column)\n",
    "        \n",
    "    df = df.filter(like='_normalized')\n",
    "\n",
    "    df[\"predictions\"] = best_rf.predict(df)\n",
    "    df['actual_weighted_score'] = df.mean(axis=1)\n",
    "    return df\n",
    "\n",
    "df_wheat_weighted = predict_weighted_score(filename)\n",
    "df_wheat_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Corn': 0.26061095473868,\n",
       " 'Soybeans': 0.30262461570911575,\n",
       " 'Wheat': 0.2539458477219761,\n",
       " 'Animal_Products': 0.3202712022131606,\n",
       " 'Fish': 0.3601322348478091,\n",
       " 'Fruit': 0.34098940106899717,\n",
       " 'Nuts': 0.3176466694389095,\n",
       " 'Vegetables': 0.31151827964578904}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AvgWeighted = {}\n",
    "for csv in [\"Corn.csv\", \"Soybeans.csv\", \"Wheat.csv\", \"Animal_Products.csv\", \"Corn.csv\", \"Fish.csv\", \"Fruit.csv\", \"Nuts.csv\", \"Soybeans.csv\", \"Vegetables.csv\", \"Wheat.csv\"]:\n",
    "    df_modeled = predict_weighted_score(csv)\n",
    "    AvgWeighted[csv[:-4]] = df_modeled['predictions'].mean()\n",
    "AvgWeighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fish',\n",
       " 'Fruit',\n",
       " 'Animal_Products',\n",
       " 'Nuts',\n",
       " 'Vegetables',\n",
       " 'Soybeans',\n",
       " 'Corn',\n",
       " 'Wheat']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = [key for key, val in sorted(AvgWeighted.items(), key=lambda item: item[1], reverse=True)]\n",
    "final_rankings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
